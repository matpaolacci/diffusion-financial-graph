{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27672a54",
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "import os\n",
    "from typing import Callable, Optional\n",
    "import pandas as pd\n",
    "from sklearn import preprocessing\n",
    "import numpy as np\n",
    "import torch\n",
    "import kagglehub\n",
    "from kagglehub import KaggleDatasetAdapter\n",
    "from graph_tool.all import *\n",
    "from torch_geometric.data import (\n",
    "    Data,\n",
    "    InMemoryDataset\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94c78ce9",
   "metadata": {},
   "source": [
    "# Load the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bf2a98e",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_name = \"LI-Small_Trans.csv\"\n",
    "\n",
    "# Load the latest version\n",
    "df = kagglehub.dataset_load(\n",
    "  KaggleDatasetAdapter.PANDAS,\n",
    "  \"ealtman2019/ibm-transactions-for-anti-money-laundering-aml\",\n",
    "  dataset_name\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "273a5384",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Uncomment the followings to free up space\n",
    "# import shutil\n",
    "# shutil.rmtree(os.path.expanduser(\"~/.cache/kagglehub/datasets/ealtman2019/\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a619bfb",
   "metadata": {},
   "source": [
    "# Look at the data\n",
    "Draw some plots..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a04cba61",
   "metadata": {},
   "source": [
    "The following table explains the meaning of each column present in the dataset\n",
    "\n",
    "| **Colonna**            | **Descrizione**                                                                 |\n",
    "|------------------------|----------------------------------------------------------------------------------|\n",
    "| Timestamp              | Year/Month/Day Hour/Minute                                                      |\n",
    "| From Bank              | Numeric code for bank where transaction originates                              |\n",
    "| Account (From)         | Hexadecimal code for account where transaction originates                       |\n",
    "| To Bank                | Numeric code for bank where transaction ends                                    |\n",
    "| Account (To)           | Hexadecimal code for account where transaction ends action ends                 |\n",
    "| Amount Received        | Monetary amount received from the source account (in currency units of the next column) |\n",
    "| Receiving Currency     | Currency such as dollars, euros, etc of From account                            |\n",
    "| Amount Paid            | Monetary amount paid (in currency units of the next column)                     |\n",
    "| Payment Currency       | Currency such as dollars, euros, etc of From account                            |\n",
    "| Payment Format         | How transaction was conducted, e.g. cheque, ACH, wire, credit cards, etc.       |\n",
    "| Is Laundering          | 0/1 value with 1 = Transaction is Laundering, 0 = Not                            |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3828016a",
   "metadata": {},
   "source": [
    "# Data Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3070a72f",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Dataset has {len(df):,.0f} rows\")\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cac43e8",
   "metadata": {},
   "source": [
    "To avoid conflicts, let's rename the bank account columns to specify the source and recipient of the transaction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d566858b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.rename(columns={'Account': 'Source Account'}, inplace=True)\n",
    "df.rename(columns={'Account.1': 'Destination Account'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73028e68",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check across all the columns of the DataFrame whether they contain empty strings or infinity values\n",
    "df.map(lambda x: x == '' or x == float('inf') or x == float('-inf') or x == np.inf or x==-np.inf).any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4af7c48a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for missing values\n",
    "for col in df.columns:\n",
    "    print(f\"Column '{col}' has {df[col].isna().sum()/df[col].count()*100:0.2f}% of missing values\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be2b21c6",
   "metadata": {},
   "source": [
    "Take a closer look at the types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a0b582c",
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in df.columns:\n",
    "    print(f\"'{col}' has '{df[col].dtype}' dtype\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22eb7162",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change the type of the column 'Timestamp' to datetime\n",
    "df['Timestamp'] = pd.to_datetime(df['Timestamp'])\n",
    "print(f\"The type of the column 'Timestamp' has been changed to '{df['Timestamp'].dtype}' dtype\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0281f18f",
   "metadata": {},
   "source": [
    "## Identifying and removing duplicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee8d7ae8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# List the duplicated rows, including the first occurrence\n",
    "duplicated_rows_map = df.duplicated(keep=False)\n",
    "print(f\"There are {duplicated_rows_map.sum()} duplicated rows in the dataset, including the first occurrence.\")\n",
    "df[duplicated_rows_map].sort_values(by=['Timestamp', 'From Bank', 'Source Account', 'To Bank', 'Destination Account'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9782cdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's drop the duplicated rows\n",
    "df.drop_duplicates(inplace=True)\n",
    "print(f\"After dropping the duplicated rows, the dataset has {df.shape[0]:,.0f} rows.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e11ca0c",
   "metadata": {},
   "source": [
    "## Look for inconsistent values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79f4bd30",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now we look for negative values in the columns containing amount value\n",
    "lower_zero = ((df['Amount Received'] < 0) | (df['Amount Paid'] < 0)).sum()\n",
    "print(f\"There are {lower_zero} rows with negative values in the columns 'Amount Received' or 'Amount Paid'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64708b2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "inconsistent_transactions = ((df['Amount Received'] != df['Amount Paid']) & (df['Receiving Currency'] == df['Payment Currency'])).sum()\n",
    "print(f\"There are {inconsistent_transactions} transactions where the amount received is not equal to the amount paid, but the currencies are the same.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da5edda4",
   "metadata": {},
   "source": [
    "# Data preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9747e146",
   "metadata": {},
   "source": [
    "In the data preprocessing, we perform below transformation:\n",
    "\n",
    "- Transform the Timestamp with min max normalization and extract some features from it (hour, day of month, month and day of the week)\n",
    "- Create unique ID for each account by adding bank code with account number.\n",
    "- Create receiving_df with the information of receiving accounts, received amount and currency\n",
    "- Create paying_df with the information of payer accounts, paid amount and currency\n",
    "- Create a list of currency used among all transactions\n",
    "- Label the 'Payment Format', 'Payment Currency', 'Receiving Currency' by classes with sklearn LabelEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bb1ff41",
   "metadata": {},
   "outputs": [],
   "source": [
    "def df_label_encoder(df, columns):\n",
    "    le = preprocessing.LabelEncoder()\n",
    "    for i in columns:\n",
    "        df[i] = le.fit_transform(df[i].astype(str))\n",
    "    return df\n",
    "    \n",
    "def preprocess(df) -> tuple[pd.DataFrame, pd.DataFrame, pd.DataFrame, list[str]]:\n",
    "    # Extract some features from the 'Timestamp'\n",
    "    df['hour'] = df['Timestamp'].dt.hour\n",
    "    df['day of month'] = df['Timestamp'].dt.day\n",
    "    df['month'] = df['Timestamp'].dt.month\n",
    "    df['weekday'] = df['Timestamp'].dt.weekday\n",
    "    \n",
    "    # Put the 'Is Laundering' as last column\n",
    "    cols = df.columns.tolist()\n",
    "    cols.remove('Is Laundering')\n",
    "    idx = cols.index('weekday') + 1\n",
    "    cols.insert(idx, 'Is Laundering')\n",
    "    df = df[cols]\n",
    "    \n",
    "    df = df_label_encoder(df,['Payment Format', 'Payment Currency', 'Receiving Currency'])\n",
    "    \n",
    "    # Scale the Timestamp feature to a real-valued range between 0 and 1 using min-max normalization\n",
    "    df['Timestamp'] = df['Timestamp'].apply(lambda x: x.value)\n",
    "    df['Timestamp'] = (df['Timestamp']-df['Timestamp'].min())/(df['Timestamp'].max()-df['Timestamp'].min())\n",
    "\n",
    "    df['Source Account'] = df['From Bank'].astype(str) + '_' + df['Source Account']\n",
    "    df['Destination Account'] = df['To Bank'].astype(str) + '_' + df['Destination Account']\n",
    "    df = df.sort_values(by=['Source Account'])\n",
    "    receiving_df = df[['Destination Account', 'Amount Received', 'Receiving Currency']]\n",
    "    paying_df = df[['Source Account', 'Amount Paid', 'Payment Currency']]\n",
    "    currency_ls = sorted(df['Receiving Currency'].unique())\n",
    "\n",
    "    return df, receiving_df, paying_df, currency_ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2244f97c",
   "metadata": {},
   "outputs": [],
   "source": [
    "edges_df, receiving_df, paying_df, currency_ls = preprocess(df)\n",
    "edges_df.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3ee935a",
   "metadata": {},
   "source": [
    "We want to extract all unique accounts from payer and receiver as node of our graph. It includes the unique account ID, Bank code and the label of 'Is Laundering'.\n",
    "In this section, we consider both payer and receiver involved in a illicit transaction as suspicious accounts, we will label both accounts with ```'Is Laundering' == 1```."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7718c451",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_nodes(df: pd.DataFrame) -> pd.DataFrame:\n",
    "\tldf = df[['Source Account', 'From Bank']]\n",
    "\trdf = df[['Destination Account', 'To Bank']] \n",
    "\n",
    "\t# Get all illicit transactions\n",
    "\tsuspicious = df[df['Is Laundering']==1]\n",
    "\n",
    "\t# Separate source and destination accounts involved in illicit transactions.\n",
    "\tsource_df = suspicious[['Source Account', 'Is Laundering']].rename({'Source Account': 'Account'}, axis=1)\n",
    "\tdestination_df = suspicious[['Destination Account', 'Is Laundering']].rename({'Destination Account': 'Account'}, axis=1)\n",
    "\n",
    "\t# Joint into a single DataFrame\n",
    "\tsuspicious = pd.concat([source_df, destination_df], join='outer')\n",
    "\n",
    "\t# An account could be involved in several illicit transactions, so we drop duplicates\n",
    "\tsuspicious = suspicious.drop_duplicates()\n",
    "\n",
    "\t# Merge the source and destination accounts with their respective banks\n",
    "\tldf = ldf.rename({'Source Account': 'Account', 'From Bank': 'Bank'}, axis=1)\n",
    "\trdf = rdf.rename({'Destination Account': 'Account', 'To Bank': 'Bank'}, axis=1)\n",
    "\tdf = pd.concat([ldf, rdf], join='outer')\n",
    "\tdf = df.drop_duplicates()\n",
    "\n",
    "\tdf['Is Laundering'] = 0\n",
    "\n",
    "\t# Mark all the transactions of the accounts involved in illicit transactions as illicit\n",
    "\tdf.set_index('Account', inplace=True)\n",
    "\tdf.update(suspicious.set_index('Account'))\n",
    "\treturn df.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "002efc8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "nodes_df = get_nodes(edges_df)\n",
    "nodes_df.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e07efde",
   "metadata": {},
   "source": [
    "# Topological properties"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8fc2354",
   "metadata": {},
   "outputs": [],
   "source": [
    "trans_graph = Graph(\n",
    "    list(edges_df[['Source Account', 'Destination Account']].itertuples(index=False, name=None)), \n",
    "    hashed=True,\n",
    "    directed=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0760c9e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#vb, eb = betweenness(trans_graph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abea0948",
   "metadata": {},
   "outputs": [],
   "source": [
    "u = GraphView(trans_graph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf6e5ea8",
   "metadata": {},
   "outputs": [],
   "source": [
    "graph_draw(u, output=\"transaction-graph.pdf\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".conda",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
